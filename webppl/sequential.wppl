var params = {
    beta: 1,
    participants: 100,
    roles: ["alice", "bob"],
    n_rounds: 10,
    closenesses: [1, 2, 3, 4],
    action_risks: [1, 2, 3],
  };

  // comfort for each scenario, based on closeness and risk
  var comfort = function (scenario, closeness, risk) {
    // format: scenario -> closeness -> risk -> comfort
    // closeness is 1-4 (not close -> extremely close), risk is 1-3 (low -> high)
    var scenarios = {
      mac: {
        1: { 1: 5, 2: 3.5, 3: 2.5 },
        2: { 1: 5.5, 2: 4.5, 3: 3.5 },
        3: { 1: 6, 2: 5, 3: 4.5 },
        4: { 1: 6, 2: 5.8, 3: 5.7 },
      },
    };

    return scenarios[scenario][closeness][risk];
  };

  var closeness_prior = Categorical({
    vs: params.closenesses,
    ps: [0.25, 0.25, 0.25, 0.25],
  });

  // base actor
  var base_actor = function (scenario, closeness_A, closeness_R) {
    return Infer({ method: "enumerate" }, function () {
      var action_risk = uniformDraw([1, 2, 3]); // prior on actions
      var U_comfort_A = comfort(scenario, closeness_A, action_risk);
      var U_comfort_R = comfort(scenario, closeness_R, action_risk);
      factor(params.beta * (U_comfort_A + U_comfort_R));
      return { action_risk: action_risk };
    });
  };

  // base receiver sees an action and infers closeness
  var base_receiver = function (scenario, closeness_R, beliefs, action_risk) {
    return Infer({ method: "enumerate" }, function () {
      var closeness_A = sample(beliefs);
      observe(base_actor(scenario, closeness_A, closeness_R), {
        action_risk: action_risk,
      });
      return { closeness_A: closeness_A };
    });
  };

  var comm_actor = function (scenario, closeness_A, beliefs) {
    return Infer({ method: "enumerate" }, function () {
      var closeness_R = sample(beliefs);
      var action_risk = uniformDraw([1, 2, 3]); // prior on actions
      var U_comfort_A = comfort(scenario, closeness_A, action_risk);
      var U_comfort_R = comfort(scenario, closeness_R, action_risk);
      factor(
        params.beta *
          (U_comfort_A +
            U_comfort_R +
            base_receiver(scenario, closeness_R, beliefs, action_risk).score({
              closeness_A: closeness_A,
            }))
      );
      return { action_risk: action_risk };
    });
  };

  // based on all the actions so far, update beliefs about closeness

  var update_posterior = function (scenario, closeness_R, beliefs, actionsSoFar) {
    return Infer({ method: "enumerate" }, function () {
      var closeness_A = sample(beliefs);
      console.log(closeness_A)

      mapData({ data: actionsSoFar }, function (action) {
        observe(base_actor(scenario, closeness_A, closeness_R), {
          action_risk: action,
        });
      });

      return {closeness_A: closeness_A};
    });
  };

  var conditions = _.flattenDeep(
    map(function (closeness_alice) {
      return map(function (closeness_bob) {
        return {
          closeness_alice: closeness_alice,
          closeness_bob: closeness_bob,
        };
      }, params.closenesses);
    }, params.closenesses)
  );

  // try to write `run` with recursion instead
  var run = function(scenario, condition, dataSoFar) {
      var alice_priors = closeness_prior;
      var bob_priors = closeness_prior;

      var alice_posterior = marginalize(update_posterior(scenario, condition.closeness_alice, alice_priors, dataSoFar.bob_actions), 'closeness_A');
      var alice_action = sample(comm_actor(scenario, condition.closeness_alice, alice_posterior));

      var bob_posterior = marginalize(update_posterior(scenario, condition.closeness_bob, bob_priors, dataSoFar.alice_actions.concat(alice_action.action_risk)), 'closeness_A');
      var bob_action = sample(comm_actor(scenario, condition.closeness_bob, bob_posterior));

      var newDataSoFar = {
          alice_actions: dataSoFar.alice_actions.concat(alice_action.action_risk),
          bob_actions: dataSoFar.bob_actions.concat(bob_action.action_risk)
      }

      if (dataSoFar.alice_actions.length < params.n_rounds) {
          return run_(scenario, condition, newDataSoFar)
      } else {
          return newDataSoFar
  }}


//   viz(update_posterior('mac', conditions[0].closeness_alice, closeness_prior, [1, 2]))

  var stuff = run("mac", conditions[0], {alice_actions: [], bob_actions: []})

  console.log(stuff.bob_actions)


  // Simulate dynamics of:
  // Two people always start out uncertain, but there is ground truth and they 'negotiate' ground truth
  // The idea is that the utilities for both people matter, there is tradeoff between utility and negotiating what the 'ground truth' is
